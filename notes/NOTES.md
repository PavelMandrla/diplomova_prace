
# Data
### <a href=http://www.cvg.reading.ac.uk/PETS2009/a.html__>PETS 2009 benchmark data</a>


# Zdroje

### [paperswithcode.com](https://paperswithcode.com/task/crowd-counting)
- soubor ƒçl√°nk≈Ø i s __odkazy na GitHub__
- jsou tam i odkazy na __datasety__, na kter√Ωch jsou ≈ôe≈°en√≠ testov√°na
- submitnut√© detektory jsou testov√°ny na zve≈ôejnƒõn√Ωch datasetech a ≈ôazeny podle √∫spƒõ≈°nosti


### [A Method for Counting Moving People in Video Surveillance Videos](https://asp-eurasipjournals.springeropen.com/articles/10.1155/2010/231240)
- Dva p≈ô√≠stupy
  - direct (detection based)
    - lid√© jsou v obraze detekov√°n√≠ (nƒõjakou formou segmentace a detekce objekt≈Ø) a n√°slednƒõ spoƒç√≠t√°ni  
    - [1]
      - syst√©m odstran√≠ pozad√≠ a n√°slednƒõ se sna≈æ√≠ matchovat modely lid√≠ s hranami v pop≈ôed√≠ (Expectation-Maximization algorithm)
      - limitace na n√≠zk√Ω poƒçet lid√≠ v "davu"
    - [2]
     - v obraze jsou detekov√°ny p≈ô√≠znaky, kter√© jsou trackov√°ny mezi jednotliv√Ωmi sn√≠mky
     - n√°slednƒõ doch√°z√≠ ke seskupov√°n√≠ bod≈Ø do skupin pomoc√≠ "Bayesian framework, under the assumption that pairs of points belonging to a same person have a small variance in their mutual distance (quasi-rigid motion)"
     - funguje i s poƒçetnƒõj≈°√≠mi davy
     - probl√©my, doch√°z√≠-li k pohybu od/ke kame≈ôe
   - [3]
    - pou≈æit√≠ 3D modelu reprezentovan√©ho elipsoidy (hlava, torso, konƒçetiny)
    - pou≈æit√≠ metody Monte Carlo s pomoc√≠ Markovov√Ωch ≈ôetƒõzc≈Ø k proveden√≠ glob√°ln√≠ optimalizace
      - je to pou≈æito na nƒõkolik sn√≠mk≈Ø
    - dobr√© na m√°lo a st≈ôednƒõ zalidnƒõn√© z√°bƒõry
    - v√Ωpoƒçetnƒõ n√°roƒçn√©
 - indirect (map based/measurement based)
   - poƒç√≠t√°n√≠ prob√≠h√° na z√°kladƒõ mƒõ≈ôen√≠ jin√© featury, kter√° nevy≈æaduje detekov√°n√≠ jednotliv√Ωch osob ve sc√©nƒõ
   - robustnƒõj≈°√≠, jeliko≈æ spr√°vn√° detekce v≈°ech osob v obraze je o≈°emetn√°
     - detekce je problematick√° nap≈ô√≠klad v davu
   - mno≈æstv√≠ pohybuj√≠c√≠ch se pixel≈Ø
   - blob size ???
   - dimenze frakt√°lu??
   - texture features
   - [8] Albiol
    - nejlep≈°√≠ v√Ωsledky na PETS2009
    - vyu≈æit√≠ roh≈Ø jako feature point≈Ø - Harris≈Øv detektor roh≈Ø
    - odstranƒõn√≠ roh≈Ø pat≈ô√≠c√≠ch pozad√≠ - nƒõjak√© prahov√°n√≠ na z√°kladƒõ velikosti pohybov√Ωch vektor≈Ø mezi jednotliv√Ωmi sn√≠mky
    - poƒçet lid√≠ je odhadnut na z√°kladƒõ poƒçtu roh≈Ø v obraze - direct corellation
     -  __smoothed mezi nƒõkolika sn√≠mky__
- navr≈æen√° metoda
  - podobn√° Albiolovi
  - sna≈æ√≠ se opravit jej√≠ omezen√≠
    - m√≠sto Harrisova detektoru se pou≈æ√≠vaj√≠ SURF p≈ô√≠znaky
      - nez√°visl√© na rotaci a ≈°k√°le objektu
    - sna≈æ√≠ se br√°t v potaz hustotu detekovan√Ωch p≈ô√≠znak≈Ø
      - mno≈æstv√≠ okluz√≠ je zvisl√© na hustotƒõ lid√≠ v obraze
        - m√°lo lid√≠ -> je nepravdƒõpodobn√©, ≈æe dojde k nƒõjak√© okluzi
        - moc lid√≠ -> budou se vz√°jemnƒõ p≈ôekr√Ωvat
      - je ale d≈Øle≈æit√© br√°t v potaz perspektivu
        - stejn√Ω poƒçet p≈ô√≠znak≈Ø bl√≠zko kamery m≈Ø≈æe b√Ωt mnohem m√©nƒõ lid√≠, ne≈æ daleko od kamery
        - doch√°z√≠ k seskupov√°n√≠ p≈ô√≠znak≈Ø do skupin
            - vzd√°lenost clusteru od kamery je odvozena pomoc√≠ vzd√°lenosti nejni≈æ≈°√≠ho a nejvy≈°≈°√≠ho bodu clusteru
    - poƒçet lid√≠ v obraze nyn√≠ nekoreluje p≈ô√≠mo k mno≈æstv√≠ p≈ô√≠znak≈Ø
      - nen√≠ to line√°rn√≠ funkce
      - m√≠sto toho je pou≈æit estim√°tor
        - SVR (support vector regressor), zalo≈æeno na SVM
        - vstup poƒçet p≈ô√≠znak≈Ø
        - v√Ωstup odhad poƒçtu lid√≠
    - v√Ωslede je podobnƒõ jako u Albiola prota≈æen low pass filtrem, tak≈æe je v√Ωsledn√° funkce v "smoothed" v ƒçase
  - detekce bod≈Ø z√°jmu
    -  p≈ôedpokl√°d√°me, ≈æe i klidn√≠ lid√© se trochu h√Ωbou
      - zaj√≠maj√≠ n√°s pouze body s nenulov√Ωm pohybov√Ωm vektorem
- poƒç√≠taj√≠ s t√≠m, ≈æe pohybuj√≠c√≠ se p≈ô√≠znaky mus√≠ pat≈ôit lidem
    - hroz√≠, ≈æe v√Ωsledky budo ovlivnƒõny proj√≠≈ædƒõj√≠c√≠mi auty a jin√Ωmi pohyby v obraze
    - buƒè p≈ôidat nƒõjakou validaci, ≈æe body opravdu pat≈ô√≠ ƒçlovƒõku, nebo pou≈æ√≠t jinou formu extrakce davu z obrazu (nap≈ô pou≈æ√≠t konvoluƒçn√≠ neuronovou s√≠≈•, kter√° bude detekovat, kde se v obraze nach√°z√≠, ƒçi nenach√°z√≠ dav a t√≠mto segmentovat obraz) samotn√Ω poƒçet lid√≠ v obraze potom poƒç√≠tat jin√Ωm zp≈Øsobem

### [Fast Video Crowd Counting with a Temporal Aware Network](https://arxiv.org/pdf/1907.02198.pdf)
- sna≈æ√≠ se vyu≈æ√≠t "_Temporal relation_"
    - mezi sn√≠mky ve videosekvenci je vztah, jeden v ƒçase p≈ôedch√°z√≠ druh√©mu
    - snaha nevych√°zet pouze z jednotliv√Ωch sn√≠mk≈Ø
    - m≈Ø≈æe to pomoci proti chyb√°m zp≈Øsoben√Ωch ≈°umem
    - jejich experimenty ukazuj√≠, ≈æe to m√° lep≈°√≠ v√Ωsledky, ne≈æ metody, kter√© vztahy mezi sn√≠mky ignoruj√≠
- pou≈æit√≠ "_Temporal Aware Network_ (TAN)"
    - dynamicky modeluje tempoln√≠ vlastnosti ve videosekvenci
    - slo≈æen√° ze dvou ƒç√°st√≠
     1. Light Convolutional Network (LCN)
        - schopn√° rychle zpracovat poƒç√≠tac√≠ √∫koly - WUT??
        - garantuje rychlost s urƒçitou p≈ôesnost√≠ detekce/v√Ωsledn√©ho poƒçtu
     2. multiple block architecture pro Temporal modeling ??
        - zab√Ωv√° se modelov√°n√≠m tempor√°ln√≠ch vztah≈Ø v ƒçase
        - ka≈æd√Ω _dilated_(roz≈°√≠≈ôen√Ω) pou≈æ√≠v√° set tempor√°ln√≠ch konvoluc√≠ ??, kter√© upadtuj√≠ odhad pro jednotliv√© sn√≠mky na z√°kladƒõ sousedn√≠ch sn√≠mk≈Ø
    - pou≈æ√≠t√≠ density map
        - sousedn√≠ sn√≠mky mohou m√≠t rozd√≠ln√Ω vizu√°ln√≠ obsah, kv≈Øli okluz√≠m a pozad√≠ (co t√≠m mysl√≠??)
        - sousedn√≠ density mapy st√°le ukazuj√≠ v√≠ce podob√©ho obsahu mezi sousedn√≠mi sn√≠mky
        - ukazuj√≠ hustotu/rozlo≈æen√≠ lid√≠
    ![TAN example](./note_pics/TAN.png)
- podobn√© pr√°ce
    - mapov√°n√≠ poƒçtu p≈ô√≠znak≈Ø na poƒçet lid√≠ (A Method for Counting Moving People in Video Surveillance Videos)
    - pou≈æ√≠t√≠ konvoluƒçn√≠ch neuronov√Ωch s√≠t√≠
        - [6] - CNN s r≈Øznƒõ velk√Ωmi konvolucemi - pom√°h√° s rozd√≠ly v hustotƒõ v obraze
            - zp≈Øsobeno perspektivou
    - ...
- architektura
    - __TAN__
        - pou≈æ√≠v√° "_dilated_" konvoluce
            - proto≈æe zpracov√°n√≠ sn√≠mku trv√° dlouho a datasety jsou omezen√©
        - zaj√≠m√° je sp√≠≈°e vztahy mezi heat mapami, ne≈æ vztahy mezi jednotliv√Ωmi sn√≠mky
            - vektory heat map jsou konkatanov√°ny a pou≈æ√≠ty jako vstupn√≠ vektor pro dal≈°√≠ pou≈æit√≠
                - pou≈æ√≠v√°m p≈ôedch√°zej√≠c√≠ i n√°sleduj√≠c√≠ sn√≠mky
        - __LCN__
            - slou≈æ√≠ k extrakci hustotn√≠ mapy z obrazu
        - Reshape and concatenation unit
            - p≈ôedƒõl√° density mapu MxN na jednodimenzion√°ln√≠ vektor
        - Dialated Residual Blocks
            - __The group of dilated residual block use the previous stage initial the next stage and use the next stage refines the previous stage.__
                - OMG WTF ????

### [Encoder-Decoder Based Convolutional Neural Networks with Multi-Scale-Aware Modules for Crowd Counting](https://arxiv.org/pdf/2003.05586v5.pdf)
- m√°m to z [paperswithcode.com](https://paperswithcode.com/task/crowd-counting) (dobr√© v√Ωsledky)
- m√° to i dostupnou [implementaci](https://github.com/Pongpisit-Thanasutives/Variations-of-SFANet-for-Crowd-Counting)
- __Introduction__
    - v novƒõj≈°√≠ch ≈ôe≈°en√≠ch jsou zd√°rnƒõ pou≈æity Konvoluƒçn√≠ neuronov√© s√≠tƒõ k vytvo≈ôen√≠ p≈ôesn√Ωch Density Map lid√≠ v obraze
        - to pom√°h√° s rozd√≠lnou distribuc√≠ lid√≠ nap≈ô√≠ƒç obrazem
            - perspektiva toti≈æ znamen√°, ≈æe skupiny d√°le od kamery budou vypadat o dost jinak, ne≈æ skupiny bl√≠zko, co≈æ zp≈Øsobuje, ≈æe p≈ôesn√° detekce je problematick√°    
        - p≈ôedchoz√≠ pr√°ce pou≈æ√≠valy _multi-column/multi-resolution_ architekturu s√≠t√≠ aby tento probl√© ≈ôe≈°ily
            - _MCNN_ - multi-column neural net?
            - podle [9] jsou ale p≈ô√≠znaky, kter√© se jednotliv√© sloupce nauƒç√≠, skoro identick√© a tr√©nov√°n√≠ takov√©to s√≠tƒõ, kter√° je u≈æ trochu v√≠ce hlubok√°, zaƒç√≠n√° b√Ωt n√°roƒçn√©
                - proto tam ([9]) navrhuj√≠ single column s√≠≈• zalo≈æenou na VGG16 Enk√≥deru/Dekod√©ru pou≈æ√≠vaj√≠c√≠ dilatovan√© konvoluce
                    - __breakthrough__ v poƒç√≠t√°n√≠ na ShanghaiTech datasetu
        - [12] poukazuje na to, ≈æe velikost pol√≠ƒçka (p≈ôedpokl√°d√°m, ≈æe t√© konvoluce) by se mƒõlo nap≈ô√≠ƒç obrazem rozd√≠lem, pr√°vƒõ kv≈Øli zmƒõnƒõ perspektivy
            - vytvo≈ôili scale-aware contextual module _CAN_ (context Aware Net)
                - dok√°≈æe z√≠sk√°vat p≈ô√≠znaky nap≈ô√≠ƒç nƒõkolika velikostmi _receptive fields_ (oblast, ze kter√© se z√≠sk√° hodnota pol√≠ƒçka v dal≈°√≠ vrstvƒõ CNN)
                ![TAN example](./note_pics/receptive_fields.png)
                - nepou≈æ√≠vaj√≠ ≈æ√°dn√© mechanismy pro redukci ≈°umu - m≈Ø≈æe doj√≠t k zanesen√≠ chyb
    - p≈ôekr√Ωv√°n√≠ objekt≈Ø
        - nejen probl√©m p≈ôi sƒç√≠t√°n√≠ davu, ale tak√© p≈ôi segmentaci obrazu
            - pro tento √∫ƒçel byly navr≈æeny jin√© _scale aware_ moduly urƒçen√© pro z√≠sk√°n√≠ kontextu√°ln√≠ch informac√≠ p≈ôi r≈Øzn√Ωch velikostech
                - _SPP_ (spatial pyramid pooling)
                - _ASSP_ (atrous spatial pyramid pooling)
        - CNN maj√≠ i dobr√© v√Ωsledky u segmentace
            - pou≈æit√≠ architektury Enkod√©r-Dekod√©r
                - takov√©to s√≠tƒõ byly nav≈æeny i pro poƒç√≠t√°n√≠ lid√≠ v obraze
- __Proposed approach__
    - dva p≈ô√≠stupy
        - oba zalo≈æen√© na architektu≈ôe Enkod√©r-Dekod√©r
    - ___M-SFANet___
        - modifikovan√° s√≠≈• _SFANet_
        - vstup projde dekod√©rem
            - _dual path multiscale fusing decoder_
            - zjist√≠ se d≈Øle≈æit√© _high level semantics_
        - n√°sldnƒõ jsou feature mapy vlo≈æeny do _multi scale aware_ modul≈Ø
            - _ASSP_ a _CAN_
        - v√Ωstupy obou cest dekod√©ru jsou slouƒçeny a pomoc√≠ biline√°rn√≠ho upsamplingu jsou _multi scale_ p≈ô√≠znaky slouƒçeny do density map a attention map
        - pak jsou pomoc√≠ attention map segmentov√°ny davy od pozad√≠
    - ___yM-SegNet___
        - modifikovan√° s√≠≈• _SegNet_

### [temporal convolutional networks for the Advance prediction of enSo](https://www.nature.com/articles/s41598-020-65070)
- vyu≈æit√≠ TCN (_temporal convolutional network_) pro p≈ôedpovƒõzen√≠ El-Ni≈àa
  - oproti RNN (_recurent neural network_) a m√° TCN mnohem lep≈°√≠ long term memory
  - oproti LSTM (vylep≈°en√° RNN, ≈ô√≠kal n√°m o n√≠ Sojka) pr√Ω vykazuje lep≈°√≠ v√Ωkon pro velmi dlouh√© sekvence input≈Ø
    - pro mƒõ mo≈æn√° zbyteƒçn√©, ale i tak je to nice
  - TCN
    - dok√°≈æe vz√≠t na vstupu jakkoliv dlouhou sekvenci a v√Ωstupem je sekvcence stejn√© d√©ly
      - stejnƒõ jakou u RNN
    - oproti LSTM pou≈æ√≠v√° pouze konvoluce
      - _casual convolution_
        - output v ƒçase t je vytvo≈ôen pouze z vzork≈Ø z ƒçasu t a m√©nƒõ - ≈æ√°dn√© informace z budoucnosti
          - __mo≈æn√° by to LSTM pro mƒõ bylo lep≈°√≠ ü§î__

### [Intro to Temporal Convolutional Networks for Time Series Forecasting in Python](https://towardsdatascience.com/temporal-coils-intro-to-temporal-convolutional-networks-for-time-series-forecasting-in-python-5907c04febc6)
- tutori√°l na TCN (_Temporal Convolutional Net_)
- _casual convolution_ - v√Ωstup je z√°visl√Ω pouze na p≈ôedch√°zej√≠c√≠ch vstupech

### [Implementace TCN + nƒõjak√© porovn√°n√≠](https://github.com/locuslab/TCN)

### DM-Count
- __Optimal tranport__
  - optim√°ln√≠ cena tranformov√°n√≠ jedn√© distribuce na druhou
    - m√°me hromadu snƒõhu, chceme z n√≠ udƒõlat jinou hromadu snƒõhu, jak√© je nejmen≈°√≠ mno≈æstv√≠ pr√°ce, kter√© na to budeme pot≈ôebovat
  - OT cost - slou≈æ√≠ pro kvantifikov√°n√≠ podobnosti dvou pravdƒõpodobnostn√≠ch distribuc√≠
- poƒç√≠t√°n√≠ lid√≠ v obraze je distribution matching probl√©my
  - jejich s√≠≈• vr√°t√≠ hustotn√≠ mapu, kterou-li zesumujeme, dostaneme poƒçet lid√≠
  - nepou≈æ√≠vaj√≠ ale gaussi√°ny
  - metoda DM-Count je agnostick√° v≈Øƒçi architektu≈ôe s√≠tƒõ
  - pro vytvo≈ôen√≠ GT mapy nepot≈ôebuje gaussi√°ny
- __Loss funkce__
  - _z_ - vektorizovan√° binin√°rn√≠ mapa pozic hlav
  - _·∫ë_ - vektorizovan√° predikovan√° hustotn√≠ mapa
  - sestaven√° ze t≈ô√≠ ƒç√°st√≠
  - ___Counting loss___
    - mƒõ≈ô√≠ rozdil mezi celkov√Ωmi hmotnostmi
    - ![Counting loss](./note_pics/counting_loss.png)
    - chceme, aby absolutn√≠ hodnota rozd√≠l≈Ø L1 norem _z_ a _·∫ë_ byla co nejmen≈°√≠
      - ide√°ln√≠ by bylo, kdyby _·∫ë_ bylo ekvivalentem t√© bin√°rn√≠ mapy, ale jeliko≈æ se d√≠v√°me poze na L1 normu, tak n√°m staƒç√≠, kdy≈æ obsah pod hustotn√≠ mapu se rovn√° obsahu t√© bin√°rn√≠ mapy
        - jeliko≈æ je obsah pod bin√°rn√≠ mapou roven poƒçtu lid√≠
  - ___OT loss___
    - mƒõ≈ô√≠ rozd√≠l mezi distribucemi normalizovan√Ωch funkc√≠ hustoty (density functions)
    - ![OT loss](./note_pics/optimal_transport_loss.png)
    - chceme, a≈• distribuce v _·∫ë_ je co nejbl√≠≈æe bin√°rn√≠ mapƒõ
      - vyu≈æijeme Optimal Transport
      - Œ±* a Œ≤* jsou ≈ôe≈°en√≠m n√°sleduj√≠c√≠ho probl√©mu
        - ![OT problem](./note_pics/OT_problem.png)
          - (v√Ωpoƒçet ceny Optimal Transport)
      - vyu≈æ√≠v√° kvadratickou cenu transportu
        - ![quadratic cost](./note_pics/quadratic_cost.png)
          - _z(i)_ a _·∫ë(j)_ jsou 2D sou≈ôadnice pozic _i_ a _j_
      - z _lOT_ dok√°≈æeme udƒõlat gradient - zderivujeme podle _·∫ë_
        - ![quadratic cost](./note_pics/OT_gradient.png)
        - ten m≈Ø≈æe b√Ωt d√°le propagov√°n do s√≠tƒõ pomoc√≠ Back propagation a dle nƒõj se m≈Ø≈æe s√≠≈• nauƒçit parametry pro odhadov√°n√≠ hustoty
  - ___Total variation loss___
    - mƒõ≈ô√≠ rozd√≠l mezi distribucemi normalizovan√Ωch funkc√≠ hustoty (density functions
      - pro aproximaci Œ±* a Œ≤* je pou≈æit sinkhorn≈Øv algoritmus
        - nƒõco o hled√°n√≠ min max sedlov√©ho bodu v matici
        - ze zaƒç√°tku konverguje rychle, ale pak se spomaluje
          - po omezen√©m mno≈æstv√≠ iterac√≠ bude hustotn√≠ mapa bl√≠zko, ale ne √∫plnƒõ identick√°
      - tento p≈ô√≠stup je dobr√Ω pro hust√© davy, ale nefunguje tak dob≈ôe pro ≈ô√≠dƒçej√≠ populovan√© oblasti ve sc√©nƒõ
        - Total variation loss ≈ôe≈°√≠ tento probl√©m
        - ![total variation loss](./note_pics/TV_loss.png)
        - z√°rove≈à zlep≈°uje stabilitu ???
      - z toho m≈Ø≈æeme vypoƒç√≠tat gradient, kter√Ω m≈Ø≈æe b√Ωt backpropagov√°n
        - ![total variation loss gradient](./note_pics/tv_loss_gradient.png)
        - ![total variation loss gradient V](./note_pics/tv_loss_v.png)
  - ___Celkov√° loss funkce___
    - je kombinac√≠ _Counting loss_, _OT loss_ a _TV loss_
    - ![total loss](./note_pics/total_loss.png)
    - ![total loss](./note_pics/min_problem.png)
